---
title: "Regression Modeling Assignment: Question 1"
author: "Fazal Mahmud Niloy (u3228358)"
date: "16/10/2022"
output: html_document
---

```{r}
library(ggplot2)
library(olsrr)

usap <- read.csv("usap.csv") 
names(usap)
```
# Question 1

## a. Making Scatter Plots of the data

```{r}
library(ggpubr)

gr <- ggplot(usap, aes(x = gr, y = vs)) + geom_point(color = "blue") + ggtitle("Vote share vs Growth rate") + xlab("Growth rate") + ylab("Vote share")
ir <- ggplot(usap, aes(x = ir, y = vs)) + geom_point(color = "green") + ggtitle("Vote share vs Inflation rate") + xlab("Inflation rate") + ylab("Vote share")
gn <- ggplot(usap, aes(x = gn, y = vs)) + geom_point(color = "red") + ggtitle("Vote share vs Good news quarters") + xlab("Good news quarters") + ylab("Vote share")
dv <- ggplot(usap, aes(x = dv, y = vs)) + geom_point(color = "magenta") + ggtitle("Vote share vs Duration value") + xlab("Duration value") + ylab("Vote share")
ggarrange(gr, ir, gn + rremove("x.text"), dv,
          ncol = 2, nrow = 2)
```

## b. Fitting three possible regression models for Vote share

#### Model A: using Growth rate, Inflation rate

```{r}
modelA <- lm(vs ~ gr + ir, data=usap)
# plot(usap$vs, usap$gr + usap$ir, ylab="Model B", main="vs ~ gr + ir")
summary(modelA)
# make a multiple regression plot
plot(modelA, which=1)
```

#### Model B: using Growth rate, Inflation rate, Good news quarters and Duration value

```{r}
modelB <- lm(vs ~ gr + ir + gn + dv, data=usap)
# plot(usap$vs, usap$gr + usap$ir + usap$gn + usap$dv, xlab="Vote Share", ylab="Model B", main="vs ~ gr + ir + gn + dv")
summary(modelB)
plot(modelB, which = 1)
```

#### Model C: using Growth rate, Inflation rate, Good news quarters, Duration value, President running, Party, and President running \* Party which is the interaction between President running and Party

```{r}
modelC <- lm(vs ~ gr + ir + gn + dv + pr + pwh + pr*pwh, data=usap)
# plot(usap$vs, usap$gr + usap$ir + usap$gn + usap$dv + usap$pr + usap$pwh + usap$pr*usap$pwh, xlab="vote share", ylab="Growth Rate", main="vs ~ gr + ir + gn + dv + pr + pwh + pr*pwh")
summary(modelC)
plot(modelC, which = 1)
```

## c. Comparing Models B and C, using the F-test with the restriction on the coefficients in the null hypothesis.

```{r}
anova(modelB, modelC)
```

From the ANOVA table we can see the F value is 3.9312 which says that the two models are significantly different. As the difference is big we would keep the better model. Now lets find the Critical value of the F distribution

Now lets find the Critical value of the F distribution:

```{r}
qf(0.05, 3, 14, lower.tail = FALSE)
```

since 3.9312 \> 3.343889, the Nested F-statistics falls in the rejection region, and we reject null hypothesis in favour of alternative Hypothesis.

#### Checking summary of modelB:

```{r}
summary(modelB)
```

#### Checking summary of modelC:

```{r}
summary(modelC)
```

As for modelC summary table ir, pr, ppr variables are non-significant and are not important for model.

From the ANOVA table we can see that alpha(0.03155) is less than 0.05, so we reject null hypothesis, thus we accept alternative hypothesis which defines at least one B5, B6, B7 is not equal to zero.

Conclusion: **modelC is better than modelB.**

## d. Comparing the fitted models from b) and choosing best model
```{r}
smryA <- summary(modelA)
smryB <- summary(modelB)
smryC <- summary(modelC)
# make dataframes for the summary with the adjusted r-squared values
model_summary <- data.frame(model=c("A", "B", "C"), adj.r.squared=c(smryA$adj.r.squared, smryB$adj.r.squared, smryC$adj.r.squared))
model_summary[which(model_summary$adj.r.squared == max(model_summary$adj.r.squared)),]
```
Since we are using "adjusted r-squared values" to measure models we can say that **model C** is the best model among 3.

## e. Presenting a scatter plot of the standardised residuals against the fitted values
```{r}
ggplot(modelC, aes (x=fitted(modelC), y=rstandard(modelC))) +
  geom_point() +
  geom_line(aes(y=0), color="red") +
  ggtitle("Standardised Residuals vs Fitted Values") +
  xlab("Fitted Values") +
  ylab("Standardised Residuals")
```
From the Residual vs fitted values scatter-plot we can see,

1. From the scatter-plot we can see that there is no specific pattern of the points thus it satisfies the independence assumption.
2. The points look fairly evenly spread out, thus it satisfies constant variance assumption.
3. The relation is non-liner

## f. For the best model from b), examining if there are any outliers or influential observations
we can find the outliers by following code:
```{r}
k <- ols_prep_cdplot_data(modelC)
outlierChart <- ols_prep_outlier_obs(k)
outlierChart$obs[outlierChart$fct_color == "outlier"]
```
as we can see, **observation 2, 8, 9 & 20 are potential outliers**. We can also visualize the outliers by using the following code:
```{r}
ols_plot_cooksd_bar(modelC)
```

## g. Using the best model from b) to make point and interval estimates for A. Gore
```{r}
predGore <- data.frame(
  gr=usap$gr[22],
  ir=usap$ir[22],
  gn=usap$gn[22],
  dv=usap$dv[22],
  pr=usap$pr[22],
  pwh=usap$pwh[22],
  "pr:pwh"=usap$pr[22]*usap$pwh[22])
predict(modelC, predGore, interval="confidence")
predict(modelC, predGore, interval="prediction")[1,1]
```
from our observation we get vote share of **49.74993% which is close to the real value 50.3%**.

# Question 2
## a. Presenting a paragraph to describe what these methods are and why they are important, and what we should be aware of when we use such methods.
#### Linear Regression:
Linear regression is a statistical method for predicting a
quantitative response using a linear combination of
explanatory variables. In this model it tries to predict a
straight line where the response variables can be fitted and
then predicted after fitting.

#### Ridge Regression:
Ridge regression is a regression analysis method that estimates
the coefficients of a linear regression model with a
shrinkage penalty on the size of the coefficients.
Ridge regression is also known as Tikhonov regularization. It can
work great to generalize a model.

#### Lasso Regression:
Lasso regression is a regression analysis method that estimates
sparse coefficients. It is also known as least absolute
shrinkage and selection operator regression. The absolute
value of slope is added as a penalty term.
It can be used to select important variables in a model.

#### Elastic Net Regression:
Elastic net regression is a regression analysis method that
combines the penalties of both ridge regression and lasso
regression.

#### KNN Regression:
KNN regression is a regression analysis method that uses
the K nearest neighbors of a data point to predict the value
of the data point. It can be used to classify data points.

## b. Describing the "Hitters" datset and its relevant background information.

This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. This is part of the data that was used in the 1988 ASA Graphics Section Poster Session. The salary data were originally from Sports Illustrated, April 20, 1987. The 1986 and career statistics were obtained from The 1987 Baseball Encyclopedia Update published by Collier Books, Macmillan Publishing Company, New York.

It is a data frame with 322 observations of major league players on the following 20 variables:

**AtBat**: Number of times at bat in 1986

**Hits**: Number of hits in 1986

**HmRun**: Number of home runs in 1986

**Runs**: Number of runs in 1986

**RBI**: Number of runs batted in in 1986

**Walks**: Number of walks in 1986

**Years**: Number of years in the major leagues

**CAtBat**: Number of times at bat during his career

**CHits**: Number of hits during his career

**CHmRun**: Number of home runs during his career

**CRuns**: Number of runs during his career

**CRBI**: Number of runs batted in during his career

**CWalks**: Number of walks during his career

**League**: A factor with levels A and N indicating player's league at the end of 1986

**Division**: A factor with levels E and W indicating player's division at the end of 1986

**PutOuts**: Number of put outs in 1986

**Assists**: Number of assists in 1986

**Errors**: Number of errors in 1986

**Salary**: 1987 annual salary on opening day in thousands of dollars

**NewLeague**: A factor with levels A and N indicating player's league at the beginning of 1987
```{r}
library(tidyverse)
library(glmnet)
library(caret)
library(ISLR)


data(Hitters, package = "ISLR")
# creating a new df to strore library data
hitters <- Hitters
head(hitters, 3)
names(hitters)
```

## c. Removing the missing values. Presenting a histogram and boxplot for the response variable salary and examine if there are any outliers.
#### Removing NA values
We are finding the number of NA values in the dataset.
```{r}
sum(is.na(hitters))
sum(is.na(hitters$Salary))
```
We can see there are *59* NA values in the dataset. Since all of the missing values are in the **Salary** column, we replace the NA values with the mean values (because these values are numeric)
```{r}
hitters$Salary[which(is.na(hitters$Salary))] <- mean(hitters$Salary, na.rm = TRUE)
sum(is.na(hitters$Salary))
max(hitters$Salary)
min(hitters$Salary)
```

#### Histogram of Salary

```{r}
hist(hitters$Salary, main="Salary", xlab="Salary")
```

#### Boxplot of Salary

```{r}
boxPltSalary <- boxplot(hitters$Salary, main="Salary", xlab="Salary")
boxPltSalary$out
```

When we run the code *"boxPltSalary$out"* we get the outliers. We can see that there are **13 outliers** in the dataset.

## d. Making a reasonable train-test split of the data. Applying a cross-validation strategy with 5-fold and presenting tuned parameter values.

#### Splitting the dataset
```{r}
# make train and test set
set.seed(123)
# Make a reasonable train-test split of the data.
# Apply a cross-validation strategy with 5-folds.
hitters_train <- hitters %>% sample_frac(0.7)
hitters_test <- setdiff(hitters, hitters_train)

# train set to get dependent variable
y_train <- hitters_train$Salary
# train set to get independent variables
x_train <- model.matrix(Salary ~ ., data = hitters_train)[,-1]

# test set to get dependent variable
y_test <- hitters_test$Salary
# test set to get independent variables
x_test <- model.matrix(Salary ~ ., data = hitters_test)[,-1]
```

## e. Presenting the regression using your training set by the five regression methods.

#### Linear Regression:
```{r}
# make linear regression model
lm <- train(Salary ~ .,
            data = hitters_train,
            method = "lm",
            trControl = trainControl(method = "cv", number = 5),
            preProcess = c("center", "scale"),
            tuneLength = 10
)
# predict
lm_pred <- predict(lm, newdata = as.data.frame(hitters_test))
metrics_lm <- data.frame(
  rmse = RMSE(y_test, as.numeric(lm_pred)),
  mae = MAE(y_test, as.numeric(lm_pred)),
  r2 = caret::R2(y_test, as.numeric(lm_pred))
)
metrics_lm
```


#### Ridge Regression:
```{r}
ridge_cv <- cv.glmnet(x_train, y_train, alpha = 0, nfolds = 5)

# best lambda value, chosen from 2 options
best_lambda <- ridge_cv$lambda.min
best_lambda

# use glmnet function to train the ridge regression
ridge_fit <- glmnet(x_train, y_train, alpha = 0, lambda = best_lambda)

# make prediction
ridge_pred <- predict(ridge_fit, s = best_lambda, newx = x_test)

metrics_ridge <- data.frame(
  rmse = RMSE(y_test, ridge_pred),
  mae = MAE(y_test, ridge_pred),
  r2 = caret::R2(y_test, ridge_pred)
)
metrics_ridge
```


#### Lasso Regression:
```{r}
# lasso: find best lamda
set.seed(123)
cv_output <- cv.glmnet(x_train, y_train, alpha = 1, nfolds = 5)

# finding the best lambda value
best_lam <- cv_output$lambda.min
best_lam

# build the lasso model with best lamda value found
best_lasso <- glmnet(x_train, y_train, alpha = 1, lambda = best_lam)

# predict
lasso_pred <- predict(best_lasso, s = best_lam, newx = x_test)

#metrics
metrics_lasso <- data.frame(
  rmse = RMSE(y_test, lasso_pred),
  mae = MAE(y_test, lasso_pred),
  r2 = caret::R2(y_test, lasso_pred)
)
metrics_lasso
```


#### Elastic Net Regression:
```{r}
# elastic net: find best lamda
set.seed(123)
model_elastic <- train(
    x = x_train,
    y = y_train,
    method = "glmnet",
    trControl = trainControl(method = "cv", number = 5),
    tuneLength = 10
    )
model_elastic$bestTune
plot(model_elastic)

y_pred <- predict(model_elastic, x_test)

metrics_elastic <- data.frame(
  rmse = RMSE(y_test, y_pred),
  mae = MAE(y_test, y_pred),
  r2 = caret::R2(y_test, y_pred)
)
metrics_elastic
```


#### KNN Regression:
```{r}
# KNN
set.seed(123)
model_knn <- train(
    x = x_train,
    y = y_train,
    method = "knn",
    trControl = trainControl(method = "cv", number = 5),
    tuneLength = 10
    )
model_knn$bestTune
plot(model_knn)

y_pred <- predict(model_knn, x_test)

matrics_knn <- data.frame(
  rmse = RMSE(y_test, y_pred),
  mae = MAE(y_test, y_pred),
  r2 = caret::R2(y_test, y_pred)
)
```

## f. Comparing and evaluating models using the test set by MAE, RMSE, and R-square measures
```{r}
# make data frame of all metrics for analysis
metrics <- data.frame()
# add cols with names
metrics <- cbind("rmse", "mae", "r2")
names(metrics) <- c("rmse", "mae", "r2")
metrics <- rbind(metrics_lm[1,])
metrics <- rbind(metrics, metrics_ridge[1,])
metrics <- rbind(metrics, metrics_lasso[1,])
metrics <- rbind(metrics, metrics_elastic[1,])
metrics <- rbind(metrics, matrics_knn[1,])
# add new col with names of models
metrics <- cbind(c("lm","ridge","lasso","elastic","knn"), metrics)
names(metrics) <- c("model", "rmse", "mae", "r2")
metrics
```
From the above dataframe *metrics* we can observe that despite having the 2nd highest RMSE **KNN** model has the

1. Highest R2 value
2. Lowest MAE value

So, we can conclude that KNN model is the best model for this dataset.

## g. Presenting a report to summarise the regression analysis
In the extensive regression analysis performed above we can see that there were different types of data in the dataset but most of them were numerical. Even which were categorical we converted them using *"model.matrix"* function. After that since all variables were numerical we performed our analysis. We partitioned our data in 70-30 ratio since it gave us the best results. As we performed our regression on all **19** variables the chances of being all of them significant was very less, but we wanted to keep our variable consistent throughout the analysis. So we used all of them against *"Salary"*. We have kept our **number of folds = 5** across all models. We have also presented our **tuned parameter values** for building different models. We performed our analysis on 5 different regression models. After building each models, we have made prediction on the test dataset and compared the test dataset with actual values. Later, we stored those comparison metrics such as **RMSE, MAE & R-Squared** to each model's corresponding dataframes. Finally, we combine all 5 metrics dataframes to one and see how each models have performed. We can see that **KNN** model performed the best. It had the **lowest MAE** and **highest R2** value even though it had the 2nd highest RMSE. So, we can conclude that KNN model is the best model for this dataset.